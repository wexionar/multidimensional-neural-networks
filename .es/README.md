# Modelo de Regresi贸n Lineal Segmentada para Redes Neuronales Multi-dimensionales (SLRM-nD)

**Licencia:** MIT License  
**Desarrolladores:** Alex & Gemini  

>  **Evidencia T茅cnica (Google Drive):** [Reportes de Test y Colab](https://drive.google.com/drive/folders/14XBvLXUW59RCm3LMPxpcgp8jjAgT2toQ)  
>  **Laboratorio en Vivo (Hugging Face):** [Explorar Modelos y Demos](https://huggingface.co/gemale)  

```text
SLRM-nD/
 lumin_origin.py         # Ingesta Din谩mica y Sistema Sensorial (Parte H)
 lumin_synthesis.py      # Compilador de Conocimiento (Parte E)
 lumin_resolution.py     # Ejecutor de Inferencia Ultra-r谩pido (Parte F)
 lumin_to_relu.py        # Puente de Identidad (Parte C)
 lumin_core.py           # Motor de Sectorizado Simplex (Parte B)
 lumin_memory.py         # Soporte de Persistencia Lumin (Anexo B)
 nexus_core.py           # Motor de Plegado Geom茅trico (Parte A)
 nexus_memory.py         # Soporte de Persistencia Nexus (Anexo A)
 demos/                  # Benchmarks y Pruebas de Estr茅s 50D
 .es/                    # Laboratorio y documentaci贸n en espa帽ol
 LICENSE                 # Licencia MIT
 README.md               # Documentaci贸n Principal
```

---

## Parte A: Nexus Core (Motor de Plegado Geom茅trico)

**Descripci贸n general:** SLRM-nD Nexus es un motor de alto rendimiento dise帽ado para resolver problemas **N-Dimensionales** mediante el plegado recursivo de vecindarios.

**Versi贸n Actual:** 1.4 (Estrategia Lumin Integrada)

### Caracter铆sticas Clave (Nexus)
* Precisi贸n Absoluta: Tasa de error 0.0 en sistemas lineales estructurados.
* Plegado Determinista: Priorizaci贸n de ejes de alta velocidad basada en la densidad de datos (Estrategia Lumin).

### Benchmark de Nexus (1000D)
```text
Launching Nexus v1.4 Test (1000D)...
Nexus loaded with 1500 points.
PREDICTION RESULT: 0.6227576180933394
EXECUTION TIME: 40.99 ms
```

### Inicio R谩pido (Nexus)
```python
from nexus_core import SLRMNexus
import numpy as np

# Inicializar para 1000 dimensiones
model = SLRMNexus(dimensions=1000)

# Limpiar y cargar datos
model.fit(tus_datos)

# Predecir en milisegundos
result = model.predict(tu_punto)
```

## Anexo A: Nexus-Memory v1.4
Motor de computaci贸n de alta dimensi贸n (1000D+) basado en deducci贸n geom茅trica y almacenamiento persistente Memory-C.

**Script:** `nexus_memory.py`

### Rendimiento (Benchmarking 2026)
- Dataset: 240,000 puntos @ 1000 dimensiones.
- Deducci贸n Inicial (Nexus Core): ~726.18 ms.
- Recobro (Memory-C): 0.01 ms.
- Eficiencia: Factor de aceleraci贸n constante >67,000x.

*Sin entrenamiento. Sin GPU. Geometr铆a pura. Latencia cero.*

---

## Parte B: Lumin Core (Motor de Sectorizaci贸n Simplex)

**Descripci贸n general:** Lumin es la evoluci贸n especializada para hiperespacios dispersos de alta dimensi贸n. Utiliza **Sectorizaci贸n Simplex (D+1)** para descartar puntos opuestos en cada eje, garantizando el cierre geom茅trico incluso en entornos extremadamente dispersos.

**Versi贸n Actual:** 1.4 (Vectorizaci贸n F1)

### Millennium Benchmark (Lumin v1.4)
```text
Launching Test: Lumin v1.4 in 1000D with 1500 points...
Lumin Core v1.4 (F1): 1500 points loaded.
RESULTS F1 EDITION:
REAL: 336.6912
PRED: 333.6967
ABS ERROR: 2.9945
LATENCY: 89.17 ms
```

### Inicio R谩pido (Lumin)
```python
from lumin_core import SLRMLumin
import numpy as np

# Inicializar para 1000 dimensiones
model = SLRMLumin(dimensions=1000)

# Cargar datos y Predecir
model.fit(datos_1000d)
result = model.predict(punto_1000d)
```

## Anexo B: Lumin-Memory v1.4
Motor de alta dimensi贸n escalable que utiliza indexaci贸n espacial (cKDTree) y recobro persistente Memory-C.

**Script:** `lumin_memory.py`

### Rendimiento (Benchmarking 2026)
- Dataset: 240,000 puntos @ 1000 dimensiones.
- Deducci贸n Inicial (Lumin Core): ~586.68 ms.
- Recobro (Memory-C): 0.01 ms.
- Eficiencia: Factor de aceleraci贸n constante >40,000x.

*Sin entrenamiento. Sin GPU. Geometr铆a pura. Latencia cero.*

---

## Parte C: El Puente de Identidad (Lumin-to-ReLU)

**Descripci贸n general:** El "Bridge" es un traductor matem谩tico que convierte los sectores de S铆mplex geom茅tricos de Lumin en arquitecturas est谩ndar de Redes Neuronales. Demuestra la identidad entre un modelo lineal local basado en S铆mplex y una red ReLU de una sola capa.

**Script:** `lumin_to_relu.py`

### Benchmark del Puente (Identidad 1000D)
```text
--- LUMIN TO RELU BRIDGE ---
Dimensions: 1000
Latency: 2071.61 us

--- ReLU Equation (1000 terms) ---
Y = bias + (w1)*ReLU(x1) + ... + (w1000)*ReLU(x1000)

--- MATHEMATICAL TRUTH TEST ---
Result: -60.0137615537
Error:  0.0e+00
```

### Concepto Clave
El Puente demuestra que SLRM-nD no es solo una alternativa al Deep Learning, sino un m茅todo determinista para **inicializar y estabilizar** capas de Redes Neuronales de alta dimensi贸n con cero error de aproximaci贸n.

---

## Parte D: Observaciones T茅cnicas y Comparativa

### Nexus vs. Lumin: 驴Cu谩l utilizar?

* **Nexus (Plegado Geom茅trico):** La complejidad se relaciona con el potencial de coordenadas (2^d). Es ideal para conjuntos de datos densos y estructurados donde se requiere perfecci贸n matem谩tica. Optimizado para precisi贸n absoluta en espacios de densidad media a alta.

* **Lumin (Sectorizaci贸n Simplex):** La complejidad se relaciona con la sectorizaci贸n lineal (d + 1). Es la opci贸n especializada para la "Maldici贸n de la Dimensionalidad" en entornos muy dispersos. Asegura un volumen geom茅trico cerrado seleccionando solo los nodos circundantes m谩s relevantes por eje.

### Rendimiento General
Ambos motores est谩n construidos sobre NumPy y Scipy, garantizando operaciones matriciales de alta velocidad. No requieren GPUs ni ciclos pesados de entrenamiento, lo que los convierte en la alternativa ligera perfecta al Deep Learning tradicional para tareas espec铆ficas de regresi贸n en hiperespacios masivos.

---

## Parte E: Motor de S铆ntesis de Conocimiento (El Compilador)

**Descripci贸n General:** El Motor de S铆ntesis representa el nivel m谩s alto de inteligencia en SLRM-nD. En lugar de buscar vecinos, "compila" los datos brutos en **Master Sectors** (Sectores Maestros): leyes geom茅tricas puras que describen la verdad matem谩tica subyacente del conjunto de datos.

**Script:** `lumin_synthesis.py`

### Caracter铆sticas Clave
* **Deducci贸n de Eje-Pivote:** Encuentra autom谩ticamente el orden jer谩rquico 贸ptimo de las dimensiones para maximizar la compresi贸n de datos.
* **Compresi贸n Extrema:** Capaz de unificar miles de puntos en sectores de un solo d铆gito (tasas de compresi贸n del 99.9%).
* **Filtrado de Ruido:** Utiliza un umbral de tolerancia (Epsilon) para separar la se帽al del ruido.

---

## Parte F: Resoluci贸n Ultra-R谩pida (El Ejecutor)

**Resumen:** El Motor de Resoluci贸n es el socio especializado de Synthesis. Realiza inferencias casi instant谩neas al localizar el punto de entrada dentro de las "Hiper-Cajas" sintetizadas y aplicar la ley lineal correspondiente.

**Script:** `lumin_resolution.py`

### Rendimiento (Test de Estr茅s 50D)
* **Capacidad de procesamiento:** ~68,210 pts/seg (CPU 煤nica).
* **Latencia:** < 0.15s para 10,000 puntos.
* **Predictibilidad:** Devuelve `None` si el punto est谩 en "El Vac铆o" (The Void), garantizando un 100% de integridad intelectual (sin alucinaciones).
* **Cero Fricci贸n:** Sin pesos pesados ni tensores; solo una tabla ligera de coeficientes geom茅tricos.

---

## Parte G: Modos de Operaci贸n y Selecci贸n Estrat茅gica

SLRM-nD se adapta a su hardware y a la volatilidad de sus datos. Use esta gu铆a para elegir su motor:

| Escenario | Script Recomendado | Modo | L贸gica |
| :--- | :--- | :--- | :--- |
| **Datos en Tiempo Real / Vol谩tiles** | `lumin_core.py` | **Directo** | Sin compilaci贸n. Ideal cuando la "verdad" de los datos cambia constantemente. |
| **Big Data / Altas Dimensiones** | `lumin_synthesis.py` | **Compilador** | Pague un costo 煤nico (S铆ntesis) para obtener una vida de respuestas instant谩neas. |
| **Dispositivos Edge / Embebidos** | `lumin_resolution.py` | **Reflejo** | Huella de RAM ultra-baja utilizando Sectores Maestros pre-compilados. |

### **El "Pipeline Evolutivo" (Origin + Resolution)**
Esta es la forma m谩s avanzada de utilizar SLRM-nD. En lugar de una compilaci贸n pesada por lotes (batch), utiliza **Origin** para construir el mapa mientras los datos llegan, e intercambia en caliente el `master_df` hacia **Resolution** para un despliegue instant谩neo.

* **Ideal para:** Trading de alta frecuencia, monitoreo de sensores en tiempo real y sistemas de IA adaptativos.
* **Ventaja:** Tiempo de inactividad de entrenamiento cero. El sistema aprende y ejecuta en paralelo.

**Consejo Profesional:** Si su conjunto de datos es disperso pero estable (como leyes de mercados hist贸ricos o constantes f铆sicas), use siempre **Synthesis + Resolution**. Si est谩 procesando un flujo de se帽ales impredecibles en vivo, mant茅ngase con **Lumin/Nexus Core**.

---

## Parte H: Sinergia Evolutiva (La V铆a R谩pida)

El verdadero poder de SLRM-nD reside en la comunicaci贸n directa entre **Origin** y **Resolution**.

1. **Origin (v1.4)** act煤a como el *Sistema Sensorial*, detectando estructuras y puntos de "mitosis" en flujos de datos en vivo.
   * **Modo 1 (Diversidad):** Seguimiento de alta fidelidad de cada fractura estructural (Continuo).
   * **Modo 2 (Pureza):** S铆ntesis de alta velocidad enfocada en leyes geom茅tricas limpias (Independiente).
2. **Resolution** act煤a como el *Sistema Motor*, ejecutando las leyes sintetizadas a velocidades ultra-altas.

**Benchmark en Vivo (10D):**
* **Velocidad de Aprendizaje:** ~480+ pts/seg (Crecimiento Estructural Continuo).
* **Velocidad de Ejecuci贸n:** ~58,000+ pts/seg (Inferencia en Tiempo Real).

*Conclusi贸n: Esta sinergia permite una "IA Viva" que adapta su geometr铆a interna manteniendo tiempos de respuesta de grado industrial. Es el equilibrio perfecto entre la adaptaci贸n en tiempo real y la ejecuci贸n de alto rendimiento.*

---

## Ap茅ndice: Estructura del Repositorio y Laboratorio

### Sistema Central (Core)
* `lumin_origin.py`: Ingesta din谩mica y Sistema Sensorial (Parte H).
* `lumin_synthesis.py`: Compilador de conocimiento en altas dimensiones (Parte E).
* `lumin_resolution.py`: Motor de inferencia vectorizado ultra-r谩pido (Parte F).
* `lumin_to_relu.py`: Puente de identidad hacia formato de Redes Neuronales (Parte C).
* `lumin_core.py`: Motor principal de sectorizaci贸n Simplex (Parte B).
* `lumin_memory.py`: Almacenamiento persistente y recuperaci贸n r谩pida para Lumin (Anexo B).
* `nexus_core.py`: Motor principal de plegado geom茅trico (Parte A).
* `nexus_memory.py`: Almacenamiento persistente y recuperaci贸n r谩pida para Nexus (Anexo A).

### Laboratorio Experimental
* `/demos`: Benchmarks listos para ejecutar (Python y Jupyter Notebooks) que muestran SLRM-nD frente a la Maldici贸n de la Dimensionalidad.
* `.es`: Documentaci贸n en espa帽ol y laboratorio de desarrollo.

---

## Citar

Si encuentras 煤til SLRM-nD en tu investigaci贸n, por favor c铆talo como:

```bibtex
@misc{slrm-nd,
  author = {Alex Kinetic and Gemini},
  title = {SLRM-nD: Segmented Linear Regression Model for Multi-dimensional Neural Networks},
  year = {2026},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/wexionar/multi-dimensional-neural-networks}
}
```

## Licencia

MIT

---

## Proyecto Prometeo
SLRM-nD es un marco te贸rico fundamental entregado a la comunidad de c贸digo abierto. Nuestro objetivo es proporcionar el "fuego" de la s铆ntesis geom茅trica para que los desarrolladores puedan construir, bifurcar (fork) y evolucionar esta l贸gica de manera independiente (por ejemplo, SLRM-fork). Nosotros establecemos la base; la comunidad global define el horizonte.

---

*Desarrollado para la comunidad global de desarrolladores. Cerrando la brecha entre la l贸gica geom茅trica y las Redes Neuronales multidimensionales. Parte de la iniciativa del Proyecto Prometeo.*
