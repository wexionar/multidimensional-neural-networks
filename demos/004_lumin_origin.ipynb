{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSowLorvBiaI9lg2G474T3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"-ltG9IYCG4wB","executionInfo":{"status":"ok","timestamp":1769109582351,"user_tz":180,"elapsed":97,"user":{"displayName":"TROMUSKRA","userId":"13446401112070935712"}}},"outputs":[],"source":["\n","# =============================================================\n","# LUMIN-DEMO 004: The Symmetric Origin Engine (High-Speed)\n","# =============================================================\n","# Project: SLRM-nD (Lumin Core)\n","# Developers: Alex Kinetic & Gemini\n","# Repository: https://github.com/wexionar/multi-dimensional-neural-networks\n","# License: MIT License\n","# Date: 2026-01-22\n","# Description: High-speed Symmetric Compression Engine.\n","#              Implements Max-Abs Scaling and Relative Epsilon\n","#              to preserve geometric integrity across nD space.\n","# =============================================================\n","\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","def run_origin_004(input_csv, output_npy, epsilon_rel=0.01):\n","    print(f\"ðŸš€ [LUMIN-ORIGIN 004] Starting compression pipeline...\")\n","\n","    # 1. DATA LOADING\n","    df = pd.read_csv(input_csv)\n","    data = df.values\n","    X = data[:, :-1]\n","    Y = data[:, -1]\n","    n_rows, n_dims = X.shape\n","\n","    # 2. SYMMETRIC NORMALIZATION (The Core Principle)\n","    # We find the Max Absolute to keep the zero centered\n","    max_abs_y = np.max(np.abs(Y))\n","    if max_abs_y == 0: max_abs_y = 1.0\n","\n","    # Work strictly in the [-1, 1] domain\n","    Y_norm = Y / max_abs_y\n","\n","    # 3. COMPRESSION ENGINE (Vectorized logic)\n","    # Epsilon is already relative, so 0.01 means 1% of the current normalized value\n","    sectors = []\n","    start_idx = 0\n","    start_time = time.perf_counter()\n","\n","    print(f\"ðŸ“¦ Processing {n_rows} rows in {n_dims}D space...\")\n","\n","    while start_idx < n_rows:\n","        end_idx = start_idx + 1\n","        found_end = False\n","\n","        # Initial sector law (from start to the next point)\n","        while end_idx < n_rows:\n","            # Multi-dimensional Linear Interpolation\n","            # We predict Y based on the line between start_idx and current end_idx\n","            if end_idx == start_idx + 1:\n","                end_idx += 1\n","                continue\n","\n","            # Current Law Weights (W) and Bias (B)\n","            # Y = X*W + B\n","            # Simplified for segments:\n","            x_start = X[start_idx]\n","            x_end = X[end_idx]\n","            y_start = Y_norm[start_idx]\n","            y_end = Y_norm[end_idx]\n","\n","            # Check intermediate points\n","            test_indices = np.arange(start_idx + 1, end_idx)\n","            # Vectorized prediction for all intermediate points\n","            # This is where we check if the sector \"absorbs\" the points\n","\n","            # Prediction logic (Linear)\n","            # t = ratio of distance (0 to 1)\n","            # Use only the first dimension for ratio if X is ordered\n","            denom = (x_end[0] - x_start[0]) if (x_end[0] - x_start[0]) != 0 else 1.0\n","            t = (X[test_indices, 0] - x_start[0]) / denom\n","            y_pred = y_start + t * (y_end - y_start)\n","\n","            errors = np.abs(Y_norm[test_indices] - y_pred)\n","            # Dynamic Relative Margin\n","            margins = np.abs(Y_norm[test_indices]) * epsilon_rel\n","\n","            # If any point exceeds its margin, the sector breaks at end_idx - 1\n","            if np.any(errors > margins):\n","                found_end = True\n","                break\n","            else:\n","                end_idx += 1\n","\n","        # Save Sector Data\n","        actual_end = end_idx - 1 if found_end else n_rows - 1\n","        if actual_end <= start_idx: actual_end = start_idx + 1\n","\n","        # Store: Mins, Maxs, Weights (simplified), Bias\n","        # [mins(D), maxs(D), weights(D), bias(1)]\n","        mins = np.min(X[start_idx:actual_end+1], axis=0)\n","        maxs = np.max(X[start_idx:actual_end+1], axis=0)\n","\n","        # Simple Law Calculation for the sector\n","        # (In v4, we use the line between boundaries for the law)\n","        w = np.zeros(n_dims)\n","        denom = (X[actual_end, 0] - X[start_idx, 0])\n","        if denom != 0:\n","            w[0] = (Y_norm[actual_end] - Y_norm[start_idx]) / denom\n","        bias = Y_norm[start_idx] - w[0] * X[start_idx, 0]\n","\n","        sector_row = np.concatenate([mins, maxs, w, [bias]])\n","        sectors.append(sector_row)\n","\n","        start_idx = actual_end\n","        if not found_end: break\n","\n","    # 4. BINARY OUTPUT WITH METADATA HEADER\n","    sectors_matrix = np.array(sectors)\n","    # Metadata Row: [MaxAbs, 0, 0, ... 0]\n","    metadata = np.zeros(sectors_matrix.shape[1])\n","    metadata[0] = max_abs_y\n","\n","    final_output = np.vstack([metadata, sectors_matrix])\n","    np.save(output_npy, final_output)\n","\n","    total_time = time.perf_counter() - start_time\n","    print(f\"âœ… Finished. Sectors created: {len(sectors)} | Time: {total_time:.4f}s\")\n","    print(f\"ðŸ’¾ Saved to: {output_npy}\")\n","\n","if __name__ == \"__main__\":\n","    # Test with dummy data or real csv\n","    # run_origin_004(\"input_data.csv\", \"origin_map.npy\")\n","    pass"]}]}