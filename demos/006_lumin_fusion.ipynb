{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLAUfZn1/tPPtUO4jnZVIP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":928},"id":"g5uzkMb3Q-J7","outputId":"2900407d-302d-42ab-de26-9439630acb33"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","    LUMIN FUSION 006 - SESSION [B00BCD39]\n","â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"," 1: Generate Synthetic Dataset\n"," 2: Load CSV file\n"," 0: Exit\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","Select option: 2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f4c5ce37-8378-45fa-9cb9-c861c207e30c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f4c5ce37-8378-45fa-9cb9-c861c207e30c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving RETO_LUMIN_01.csv to RETO_LUMIN_01.csv\n","\n","â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","    ENGINE CONFIGURATION\n","â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","ğŸ“ PARAMETERS: Norm(1:Sim/2:Dir), Eps Type(1:Abs/2:Rel), Eps Val, Mode(1:Div/2:Pur)\n",">> [Enter for 1, 1, 0.05, 1]: 1, 1, 0.1, 2\n","\n","ğŸš€ PROCESSING SESSION B00BCD39...\n","\n","ğŸ“Š IGNITION REPORT: B00BCD39\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","â€¢ STRATEGY:      PURITY (Mode 2)\n","â€¢ NORMALIZATION: SYMMETRIC [-1, 1]\n","â€¢ EPSILON:       0.1 (ABSOLUTE)\n","â€¢ PRECISION:     0.06608 MAE (93.39% Fidelity)\n","â€¢ Y-RANGE:       [-14.74 to 8.29]\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","â€¢ PROCESSED:     15,000 points | 10D\n","â€¢ SECTORS:       6051 detected\n","â€¢ COMPRESSION:   59.66%\n","â€¢ MAP SIZE:      1.43 MB\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","â€¢ LEARNING SPD:  11,926.55 pts/sec\n","â€¢ THROUGHPUT:    119,265.45 ops/sec\n","â€¢ LATENCY:       1.2577 sec\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","ğŸ”¥ STARTING RESOLUTION STRESS TEST (1000 Points)...\n","ğŸš€ VECTORIZED THROUGHPUT: 1,046.14 ops/sec\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","What would you like to do now, colleague?\n"," 1: Return to start (New Ingestion/Parameters)\n"," 2: Exit and Save .npy file\n"," 0: Exit (Without saving)\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"]}],"source":["\n","# =============================================================\n","# LUMIN-DEMO 006: The Integrated Fusion Engine (Symmetry & Precision)\n","# =============================================================\n","# Project: SLRM-nD (Lumin Core)\n","# Developers: Alex Kinetic & Gemini\n","# Repository: https://github.com/wexionar/multi-dimensional-neural-networks\n","# License: MIT License\n","# Date: 2026-01-24\n","# Description: Advanced unified engine for ingestion and\n","#              high-speed vectorized resolution. Synchronized\n","#              multi-dimensional sectors for real-world\n","#              benchmarking and structural synthesis.\n","# =============================================================\n","\n","import numpy as np\n","import pandas as pd\n","import io\n","import time\n","import secrets\n","import os\n","\n","# --- ENVIRONMENT DETECTION ---\n","try:\n","    from google.colab import files\n","    IN_COLAB = True\n","except ImportError:\n","    IN_COLAB = False\n","\n","# =============================================================\n","# CORE 1: LUMIN ORIGIN\n","# =============================================================\n","class LuminOrigin:\n","    def __init__(self, epsilon_val=0.05, epsilon_type=1, mode_type=1):\n","        self.epsilon_val = epsilon_val\n","        self.epsilon_type = int(epsilon_type)\n","        self.mode = 'diversity' if mode_type == 1 else 'purity'\n","        self.mode_label = \"DIVERSITY (Mode 1)\" if mode_type == 1 else \"PURITY (Mode 2)\"\n","        self.master_sectors = []\n","        self.current_sector_nodes = []\n","        self.D = None\n","\n","    def _calculate_law(self, nodes):\n","        if len(nodes) < 2: return None, None\n","        nodes_np = np.array(nodes)\n","        X, Y = nodes_np[:, :-1], nodes_np[:, -1]\n","        A_mat = np.c_[X, np.ones(X.shape[0])]\n","        try:\n","            res = np.linalg.lstsq(A_mat, Y, rcond=None)[0]\n","            return res[:-1], res[-1]\n","        except: return None, None\n","\n","    def _close_sector(self):\n","        if len(self.current_sector_nodes) < 2: return\n","        nodes = np.array(self.current_sector_nodes)\n","        W, B = self._calculate_law(self.current_sector_nodes)\n","        if W is not None:\n","            sector = np.concatenate([\n","                np.min(nodes[:, :-1], axis=0),\n","                np.max(nodes[:, :-1], axis=0),\n","                W, [B]\n","            ])\n","            self.master_sectors.append(sector)\n","\n","    def ingest(self, cell):\n","        cell_np = np.array(cell, dtype=float)\n","        y_real = cell_np[-1]\n","        if self.D is None: self.D = len(cell_np) - 1\n","        if len(self.current_sector_nodes) < 2:\n","            self.current_sector_nodes.append(cell_np.tolist())\n","            return\n","        W, B = self._calculate_law(self.current_sector_nodes)\n","        y_pred = np.dot(cell_np[:-1], W) + B\n","        error_abs = abs(y_real - y_pred)\n","        threshold = self.epsilon_val if self.epsilon_type == 1 else abs(y_real) * self.epsilon_val\n","        if error_abs <= threshold:\n","            self.current_sector_nodes.append(cell_np.tolist())\n","        else:\n","            self._close_sector()\n","            self.current_sector_nodes = [self.current_sector_nodes[-1], cell_np.tolist()] if self.mode == 'diversity' else [cell_np.tolist()]\n","\n","# =============================================================\n","# CORE 2: LUMIN RESOLUTION\n","# =============================================================\n","class LuminResolution:\n","    def __init__(self, sectors):\n","        self.sectors = np.array(sectors)\n","        self.D = (self.sectors.shape[1] - 1) // 3\n","        self.mins = self.sectors[:, :self.D]\n","        self.maxs = self.sectors[:, self.D : 2*self.D]\n","        self.weights = self.sectors[:, 2*self.D : 3*self.D]\n","        self.biases = self.sectors[:, -1]\n","\n","    def resolve(self, X_input):\n","        X = np.atleast_2d(X_input)\n","        inside = np.all((X[:, np.newaxis, :] >= self.mins - 1e-9) &\n","                        (X[:, np.newaxis, :] <= self.maxs + 1e-9), axis=2)\n","        has_sector = np.any(inside, axis=1)\n","        indices = np.argmax(inside, axis=1)\n","        results = np.full(X.shape[0], np.nan)\n","        if np.any(has_sector):\n","            results[has_sector] = np.einsum('ij,ij->i', X[has_sector], self.weights[indices[has_sector]]) + self.biases[indices[has_sector]]\n","        return results\n","\n","# =============================================================\n","# FLOW CONTROL: LUMIN FUSION 006\n","# =============================================================\n","def start_fusion_006():\n","    session_token = secrets.token_hex(4).upper()\n","    cache_data = None  # <-- PERSISTENCE\n","\n","    while True:\n","        raw_data = None\n","\n","        # --- 1. INGESTION ---\n","        while raw_data is None:\n","            print(\"\\n\" + \"â•\"*45 + f\"\\n    LUMIN FUSION 006 - SESSION [{session_token}]\\n\" + \"â•\"*45)\n","            print(\" 1: Generate Synthetic Dataset\\n 2: Load CSV file\")\n","            if cache_data is not None:\n","                print(f\" 3: Re-use dataset in memory ({len(cache_data):,} pts)\")\n","            print(\" 0: Exit\\n\" + \"â”€\"*45)\n","\n","            mode_select = input(\"Select option: \").strip() or \"1\"\n","            if mode_select == \"0\": return\n","\n","            if mode_select == \"1\":\n","                sug = \"10000, 50, 100, 2\"\n","                print(\"\\nğŸ“ CONFIGURATION: Points, Dims, Range, Type(1:Pos/2:Both)\")\n","                user_params = input(f\">> [Enter for {sug}]: \").strip() or sug\n","                try:\n","                    params = [float(x.strip()) for x in user_params.split(\",\")]\n","                    N, D, R_MAX, DATA_TYPE = int(params[0]), int(params[1]), params[2], int(params[3])\n","                    X = np.random.uniform(-R_MAX, R_MAX, (N, D)) if DATA_TYPE == 2 else np.random.uniform(0, R_MAX, (N, D))\n","                    Y = (np.sum(X, axis=1) / D) + np.random.normal(0, 0.01, N)\n","                    raw_data = np.hstack([X, Y.reshape(-1, 1)])\n","                    cache_data = raw_data # Save\n","                except Exception as e: print(f\"âŒ Error: {e}\")\n","            elif mode_select == \"2\":\n","                if not IN_COLAB: print(\"âš ï¸ Colab environment required.\"); continue\n","                uploaded = files.upload()\n","                if not uploaded: continue\n","                df = pd.read_csv(io.BytesIO(uploaded[list(uploaded.keys())[0]]))\n","                raw_data = df.to_numpy()\n","                cache_data = raw_data # Save\n","            elif mode_select == \"3\" and cache_data is not None:\n","                raw_data = cache_data\n","\n","        # --- 2. ENGINE CONFIGURATION ---\n","        print(\"\\n\" + \"â•\"*45 + \"\\n    ENGINE CONFIGURATION\\n\" + \"â•\"*45)\n","        print(\"ğŸ“ PARAMETERS: Norm(1:Sim/2:Dir), Eps Type(1:Abs/2:Rel), Eps Val, Mode(1:Div/2:Pur)\")\n","        cfg_sug = \"1, 1, 0.05, 1\"\n","        cfg_data = input(f\">> [Enter for {cfg_sug}]: \").strip() or cfg_sug\n","        try:\n","            config = [float(x.strip()) for x in cfg_data.split(\",\")]\n","            n_type, e_type, e_val, m_type = int(config[0]), int(config[1]), config[2], int(config[3])\n","        except:\n","            n_type, e_type, e_val, m_type = 1, 1, 0.05, 1\n","\n","        # --- 3. ORIGIN EXECUTION ---\n","        print(f\"\\nğŸš€ PROCESSING SESSION {session_token}...\")\n","        s_min, s_max = raw_data.min(axis=0), raw_data.max(axis=0)\n","        s_range = np.where((s_max - s_min) == 0, 1e-9, s_max - s_min)\n","\n","        if n_type == 1:\n","            data_norm = 2 * (raw_data - s_min) / s_range - 1\n","            norm_label = \"SYMMETRIC [-1, 1]\"\n","        else:\n","            data_norm = (raw_data - s_min) / s_range\n","            norm_label = \"DIRECT [0, 1]\"\n","\n","        origin = LuminOrigin(epsilon_val=e_val, epsilon_type=e_type, mode_type=m_type)\n","        t_start = time.perf_counter()\n","        for point in data_norm: origin.ingest(point)\n","        t_end = time.perf_counter()\n","\n","        # METRICS\n","        duration = t_end - t_start\n","        pts, dims = len(raw_data), raw_data.shape[1] - 1\n","        sectors_list = origin.master_sectors\n","        num_sectors = len(sectors_list)\n","        comp_ratio = (1 - num_sectors/pts) * 100 if pts > 0 else 0\n","        speed = pts / duration\n","        throughput = (pts * dims) / duration\n","\n","        mae_val, fidelity = 0.0, 0.0\n","        if num_sectors > 0:\n","            res_val = LuminResolution(sectors_list)\n","            y_pred = res_val.resolve(data_norm[:, :-1])\n","            valid_mask = ~np.isnan(y_pred)\n","            if np.any(valid_mask):\n","                mae_val = np.mean(np.abs(data_norm[valid_mask, -1] - y_pred[valid_mask]))\n","                fidelity = max(0, (1 - mae_val) * 100)\n","\n","        estimated_weight_bytes = num_sectors * (dims * 3 + 1) * 8\n","        weight_str = f\"{estimated_weight_bytes/1024:.2f} KB\" if estimated_weight_bytes < 1024*1024 else f\"{estimated_weight_bytes/(1024*1024):.2f} MB\"\n","\n","        print(\"\\nğŸ“Š IGNITION REPORT: \" + session_token)\n","        print(\"â”€\"*45)\n","        print(f\"â€¢ STRATEGY:      {origin.mode_label}\")\n","        print(f\"â€¢ NORMALIZATION: {norm_label}\")\n","        print(f\"â€¢ EPSILON:       {e_val} ({'RELATIVE %' if e_type == 2 else 'ABSOLUTE'})\")\n","        print(f\"â€¢ PRECISION:     {mae_val:.5f} MAE ({fidelity:.2f}% Fidelity)\")\n","        print(f\"â€¢ Y-RANGE:       [{s_min[-1]:,.2f} to {s_max[-1]:,.2f}]\")\n","        print(\"â”€\"*45)\n","        print(f\"â€¢ PROCESSED:     {pts:,} points | {dims}D\")\n","        print(f\"â€¢ SECTORS:       {num_sectors} detected\")\n","        print(f\"â€¢ COMPRESSION:   {comp_ratio:.2f}%\")\n","        print(f\"â€¢ MAP SIZE:      {weight_str}\")\n","        print(\"â”€\"*45)\n","        print(f\"â€¢ LEARNING SPD:  {speed:,.2f} pts/sec\")\n","        print(f\"â€¢ THROUGHPUT:    {throughput:,.2f} ops/sec\")\n","        print(f\"â€¢ LATENCY:       {duration:.4f} sec\")\n","        print(\"â”€\"*45)\n","\n","        # --- 4. RESOLUTION TEST ---\n","        if num_sectors > 0:\n","            n_stress = 1000\n","            print(f\"\\nğŸ”¥ STARTING RESOLUTION STRESS TEST ({n_stress} Points)...\")\n","            res_engine = LuminResolution(sectors_list)\n","            t_min, t_max = (-1, 1) if n_type == 1 else (0, 1)\n","            test_points = np.random.uniform(t_min, t_max, (n_stress, dims))\n","            t_res_start = time.perf_counter()\n","            _ = res_engine.resolve(test_points)\n","            t_res_end = time.perf_counter()\n","            throughput_res = n_stress / (t_res_end - t_res_start)\n","            print(f\"ğŸš€ VECTORIZED THROUGHPUT: {throughput_res:,.2f} ops/sec\")\n","            print(\"â”€\"*45)\n","\n","        # --- 5. EXIT ---\n","        print(\"\\nWhat would you like to do now, colleague?\")\n","        print(\" 1: Return to start (New Ingestion/Parameters)\")\n","        print(\" 2: Exit and Save .npy file\")\n","        print(\" 0: Exit (Without saving)\")\n","        print(\"â”€\"*45)\n","\n","        post_action = input(\">> Select: \").strip() or \"1\"\n","        if post_action == \"1\": continue\n","        elif post_action == \"2\":\n","            filename = f\"LUMIN_DATA_{session_token}.npy\"\n","            np.save(filename, {\n","                'sectors': sectors_list,\n","                'token': session_token,\n","                'dims': dims,\n","                'norm_type': n_type,\n","                's_min': s_min,\n","                's_range': s_range,\n","                'epsilon_type': e_type,\n","                'epsilon_val': e_val\n","            })\n","            print(f\"\\nâœ… SAVED: {filename}\")\n","            if IN_COLAB: files.download(filename)\n","            break\n","        elif post_action == \"0\": break\n","\n","start_fusion_006()"]}]}